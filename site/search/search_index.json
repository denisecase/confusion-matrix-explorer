{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Confusion Matrix Explorer (PyShiny App)","text":"<p>This repo (<code>confusion-matrix-explorer</code>) contains a PyShiny app for exploring how changing a decision threshold affects a binary classifier confusion matrix and related metrics (sensitivity, specificity, precision, etc.).</p>"},{"location":"#prerequisites-set-up-machine","title":"Prerequisites: Set Up Machine","text":"<ul> <li>View hidden files and folders</li> <li>View file extensions</li> <li>Git</li> <li>VS Code (recommended)</li> <li>uv</li> </ul>"},{"location":"#fork-and-clone-repository","title":"Fork and Clone Repository","text":"<ol> <li>Fork the repo.</li> <li>Clone your repo to your machine and open it in VS Code.</li> </ol> <p>Open a terminal and run the following commands.</p> <pre><code>git clone https://github.com/YOUR_USERNAME/confusion-matrix-explorer.git\ncd confusion-matrix-explorer\n</code></pre>"},{"location":"#dev-1-one-time-setup","title":"Dev 1. One-time setup","text":"<ul> <li>Open the repo directory in VS Code.</li> <li>Open a terminal in VS Code.</li> </ul> <pre><code>uv python pin 3.12\nuv venv\n\n.venv\\Scripts\\activate # Windows\n# source .venv/bin/activate  # Mac/Linux/WSL\n\nuv sync --extra dev --extra docs --upgrade\nuv run pre-commit install\nuv run shiny run --reload src/confusion_matrix_explorer/app.py\n</code></pre>"},{"location":"#about-the-app","title":"About the App","text":"<p>This app demonstrates how changing the decision threshold (the vertical T line) affects the confusion matrix and related metrics (sensitivity, specificity, etc.) for a binary classification problem.</p> <p>How to Use</p> <ul> <li>Use the sidebar upper slider to vary the decision threshold.</li> <li>Use the sidebar lower slider to vary the number of bins in the histogram.</li> <li>Compare the as you raise (or lower) the decision threshold.</li> </ul>"},{"location":"#screenshot-raise-the-bar","title":"Screenshot (Raise the Bar)","text":""},{"location":"#screenshot-default","title":"Screenshot (Default)","text":""},{"location":"#screenshot-lower-the-bar","title":"Screenshot (Lower the Bar)","text":""},{"location":"ABOUT/","title":"Confusion Matrix Explorer","text":"<p>Confusion Matrix Explorer is an interactive learning app that helps users see how changing a decision threshold affects model performance. It demonstrates, in real time, how raising or lowering the bar shifts the balance between sensitivity, specificity, and other diagnostic metrics.</p> <p>Built with PyShiny, Plotly, and NumPy, the app provides a visual way to understand one of the most important tradeoffs in classification modeling.</p>"},{"location":"ABOUT/#concept-overview","title":"Concept Overview","text":"<p>In any binary classification task - whether detecting diseases, fraud, or spam - the model assigns each case a score (often a probability). To make a final decision, we choose a threshold.</p> <ul> <li>If the score \u2265 threshold &gt; we predict positive</li> <li>If the score &lt; threshold &gt; we predict negative</li> </ul> <p>Changing that threshold is what we call raising or lowering the bar.</p>"},{"location":"ABOUT/#raising-the-bar-more-specific","title":"Raising the Bar (More Specific)","text":"<p>Raising the bar means making it harder to call something positive.  The threshold line moves to the right.</p> <ul> <li>Fewer positives overall</li> <li>More False Negatives (missed detections)</li> <li>Higher Specificity (fewer false alarms)</li> <li>Lower Sensitivity (catch fewer real cases) </li> <li>Precision (PPV) often increases - you're more confident in what you call positive.</li> </ul> <p>This is like a very strict test: you'll rarely call someone \"positive,\" but when you do, you're pretty sure.</p>"},{"location":"ABOUT/#lowering-the-bar-more-sensitive","title":"Lowering the Bar (More Sensitive)","text":"<p>Lowering the bar means making it easier to call something \"positive.\" The threshold line moves to the left.</p> <ul> <li>More positives overall</li> <li>More False Positives (false alarms)</li> <li>Lower Specificity</li> <li>Higher Sensitivity (catch nearly everyone with the condition) </li> <li>Precision (PPV) often decreases - more of your \"positives\" turn out to be wrong.</li> </ul> <p>This is like a very sensitive test: you'll catch almost everyone who's sick, but you'll also flag some healthy people.</p>"},{"location":"ABOUT/#the-confusion-matrix","title":"The Confusion Matrix","text":"<p>Every threshold creates a confusion matrix, a 2\u00d72 table that summarizes prediction outcomes:</p> Disease Present Disease Absent Test Positive True Positive (TP) False Positive (FP) Test Negative False Negative (FN) True Negative (TN) <p>From these four counts, we derive all the key diagnostic metrics.</p>"},{"location":"ABOUT/#calculations","title":"Calculations","text":"<p>Let a = TP, b = FN, c = FP, d = TN, and N = a + b + c + d.</p> Metric Formula Meaning Sensitivity (TPR) a / (a + b) Probability the test is positive given disease is present Specificity (TNR) d / (c + d) Probability the test is negative given disease is absent Precision (PPV) a / (a + c) Probability the disease is present given a positive test Negative Predictive Value (NPV) d / (b + d) Probability the disease is absent given a negative test Accuracy (a + d) / N Overall proportion correctly classified Prevalence (a + b) / N Fraction of total population that truly has the disease <p>Note: These values depend on both model behavior and population prevalence. A highly accurate test in one population may perform differently in another.</p>"},{"location":"ABOUT/#visualization","title":"Visualization","text":"<p>The app displays two overlapping score distributions:</p> <ul> <li>One showing counts where the disease is present </li> <li>One showing counts where the disease is absent</li> </ul> <p>The vertical dashed line (\"T line) marks the decision threshold.</p> <ul> <li>Moving the line right &gt; raises the bar &gt; increases specificity, decreases sensitivity.  </li> <li>Moving it left &gt; lowers the bar &gt; increases sensitivity, decreases specificity.</li> </ul> <p>Each update recomputes the confusion matrix and metrics to illustrate tradeoffs.</p>"},{"location":"ABOUT/#see-also","title":"See Also","text":"<ol> <li>PyCM (Python Confusion Matrix)</li> <li>Scikit-learn confusion_matrix</li> <li>Evidently: Confusion Matrix Dashboard</li> </ol>"},{"location":"ABOUT/#author-and-license","title":"Author and License","text":"<p>Developed by Denise Case \u00a9 2025 MIT License</p>"},{"location":"DEVELOPER/","title":"DEVELOPER.md","text":""},{"location":"DEVELOPER/#prerequisites-set-up-machine","title":"Prerequisites: Set Up Machine","text":"<ul> <li>View hidden files and folders</li> <li>View file extensions</li> <li>Git</li> <li>VS Code (recommended)</li> <li>uv</li> </ul>"},{"location":"DEVELOPER/#fork-and-clone-repository","title":"Fork and Clone Repository","text":"<ol> <li>Fork the repo.</li> <li>Clone your repo to your machine and open it in VS Code.</li> </ol> <p>Open a terminal and run the following commands.</p> <pre><code>git clone https://github.com/YOUR_USERNAME/confusion-matrix-explorer.git\ncd confusion-matrix-explorer\n</code></pre>"},{"location":"DEVELOPER/#dev-1-one-time-setup","title":"Dev 1. One-time setup","text":"<ul> <li>Open the repo directory in VS Code.</li> <li>Open a terminal in VS Code.</li> </ul> <pre><code>uv python pin 3.12\nuv venv\n\n.venv\\Scripts\\activate # Windows\n# source .venv/bin/activate  # Mac/Linux/WSL\n\nuv sync --extra dev --extra docs --upgrade\nuv run pre-commit install\nuv run shiny run --reload src/confusion_matrix_explorer/app.py\n</code></pre>"},{"location":"DEVELOPER/#dev-2-validate-local-changes","title":"Dev 2. Validate Local Changes","text":"<pre><code>git pull origin main\nuvx pre-commit autoupdate\ngit add .\nuvx ruff check . --fix\nuvx ruff format .\nuvx deptry .\nuv run pyright\nuv run pytest\n</code></pre> <p>Run the pre-commit hooks (twice, if needed):</p> <pre><code>pre-commit run --all-files\n</code></pre>"},{"location":"DEVELOPER/#dev-3-build-and-preview-docs","title":"DEV 3. Build and Preview Docs","text":"<pre><code>uv run mkdocs build --strict\nuv run mkdocs serve\n</code></pre> <p>Verify local API docs at: http://localhost:8000 When done reviewing, use CTRL c or CMD c to quit.</p>"},{"location":"DEVELOPER/#dev-4-test","title":"DEV 4. Test","text":"<p>Update <code>CHANGELOG.md</code> and <code>pyproject</code>.toml dependencies. Ensure CI passes.</p> <pre><code>git add .\nuv run pre-commit run --all-files\nuv run pytest -q\n</code></pre>"},{"location":"DEVELOPER/#dev-5-git-add-commit-push-changes","title":"DEV 5. Git add-commit-push Changes","text":"<pre><code>git add .\ngit commit -m \"Prep vx.y.z\"\ngit push -u origin main\n</code></pre>"},{"location":"DEVELOPER/#dev-8-git-tag-and-push-tag","title":"DEV 8. Git tag and Push tag","text":"<p>Important: Wait for GitHub Actions from prior step to complete successfully (all green checks). If any fail, fix issues and push again before tagging.</p> <pre><code>git tag vx.y.z -m \"x.y.z\"\ngit push origin vx.y.z\n</code></pre>"}]}